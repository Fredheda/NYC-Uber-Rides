{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adapted-complexity",
   "metadata": {},
   "source": [
    "# Intermediate Regression Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-removal",
   "metadata": {},
   "source": [
    "### DISCLAIMER:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-weapon",
   "metadata": {},
   "source": [
    "<strong>This Notebook is part of a Capstone Project. Some analysis & preprocessing steps, as well as scaling, encoding and transformation, and other data pipeline steps are intentially left out to demonstrate the difference between simplistic regression models and more advanced regression models which are included in other notebooks within this repository. This notebook intentionally does not adhere to best practices.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import calendar\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results():\n",
    "    error_list = [abs(i-j) for i,j in zip(Y_test,y_test_pred)]\n",
    "    result_df = pd.DataFrame(zip(Y_test,y_test_pred,error_list),columns=([\"Ground Truth\",\"Prediction\",\"Absolute Error\"]))\n",
    "    result_df = result_df[(result_df[\"Ground Truth\"] > 0) & (result_df[\"Ground Truth\"] < 150)]\n",
    "    \n",
    "    fig = px.scatter(result_df,x=\"Ground Truth\", y=\"Prediction\",width=1500, height=600,\n",
    "                     labels=dict(x=\"Ground Truth\", y=\"Prediction\"), color=\"Absolute Error\")\n",
    "\n",
    "\n",
    "    fig.update_xaxes(title_font=dict(size=35, color='black'))\n",
    "    fig.update_yaxes(title_font=dict(size=35, color='black'))\n",
    "    fig.update_xaxes(zeroline=False)\n",
    "    fig.update_yaxes(zeroline=False)\n",
    "\n",
    "    fig.update_xaxes(range=[0, 100])\n",
    "    fig.update_yaxes(range=[0, 120])\n",
    "\n",
    "    title=\"Regression Prediction Results compared to Ground Truth\"\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "def data_types(df):\n",
    "    return pd.DataFrame(df.dtypes.value_counts(),columns=([\"count\"]))\n",
    "\n",
    "def check_num_OHC(df):\n",
    "    categorical_cols = df.columns[df.dtypes == object]\n",
    "    num_OHC_cols = pd.DataFrame(df[categorical_cols]\n",
    "                .apply(lambda x: x.nunique())\n",
    "                .sort_values(ascending=False), columns=([\"count\"]))\n",
    "    \n",
    "    #if column only has one category, column is irrelevant for encoding\n",
    "    num_OHC_cols = num_OHC_cols[\"count\"].loc[num_OHC_cols[\"count\"]>=2]\n",
    "    \n",
    "    num_OHC_cols -=1\n",
    "    \n",
    "    return num_OHC_cols.sum()\n",
    "\n",
    "def create_OHC_dataframe(df):\n",
    "    \n",
    "    #create copy of dataframe\n",
    "    df_OHC = df.copy()\n",
    "    \n",
    "    #create encoder objects\n",
    "    le = LabelEncoder()\n",
    "    ohc = OneHotEncoder()\n",
    "\n",
    "    #create filter for categorical columns\n",
    "    categorical_cols = df.columns[df.dtypes == object]\n",
    "    num_OHC_cols = (df[categorical_cols]\n",
    "                    .apply(lambda x: x.nunique())\n",
    "                    .sort_values(ascending=False))\n",
    "\n",
    "    for col in num_OHC_cols.index:\n",
    "\n",
    "        # Integer encode the string categories\n",
    "        encoded_cols = le.fit_transform(df_OHC[col]).astype(np.int)\n",
    "\n",
    "        # Remove the original column from the dataframe\n",
    "        df_OHC = df_OHC.drop(col, axis=1)\n",
    "\n",
    "        # One hot encode the data--this returns a sparse array\n",
    "        OHC_cols = ohc.fit_transform(encoded_cols.reshape(-1,1))\n",
    "\n",
    "        # Create unique column names\n",
    "        num_cols = OHC_cols.shape[1]\n",
    "        col_names = ['_'.join([col, str(x)]) for x in range(num_cols)]\n",
    "\n",
    "        # Create the new dataframe\n",
    "        new_df = pd.DataFrame(OHC_cols.toarray(), \n",
    "                              index=df_OHC.index, \n",
    "                              columns=col_names)\n",
    "\n",
    "        # Append the new data to the dataframe\n",
    "        df_OHC = pd.concat([df_OHC, new_df], axis=1)\n",
    "\n",
    "    return df_OHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"uber_preprocessed.csv\")\n",
    "df.drop(\"Unnamed: 0\",inplace=True,axis=1)\n",
    "\n",
    "# Drop Columns that are not relevant for prediction\n",
    "df.drop([\"date\",\"time\",\"minute\",\"second\"],axis=1,inplace=True)\n",
    "\n",
    "df.year = df.year.apply(lambda x: str(x))\n",
    "df.month = df.month.apply(lambda x: calendar.month_name[x])\n",
    "df.day_of_week = df.day_of_week.apply(lambda x: calendar.day_name[x])\n",
    "df.day = df.day.apply(lambda x: str(x))\n",
    "df.hour = df.hour.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One-Hot_Encoding would add \",check_num_OHC(df),\" Columns to the Dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-contract",
   "metadata": {},
   "source": [
    "One Hot Encoding is used for the following columns:\n",
    "- year\n",
    "- month\n",
    "- day\n",
    "- hour\n",
    "- day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_OHC_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"fare_amount\"\n",
    "features = [col for col in df.columns.tolist() if col != \"fare_amount\"]\n",
    "\n",
    "X = df[features]\n",
    "Y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-intervention",
   "metadata": {},
   "source": [
    "## Polynomial Features & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaler\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Object\n",
    "LR = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = Pipeline([\n",
    "    (\"scaler\", scaler),\n",
    "    (\"make_higher_degree\", PolynomialFeatures(degree=2)),\n",
    "    (\"Linear Regression\", LR)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_estimator.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error DataFrame\n",
    "error_df = []\n",
    "error_df.append(pd.Series({'train': mean_squared_error(Y_train, y_train_pred),\n",
    "                           'test' : mean_squared_error(Y_test,  y_test_pred)},\n",
    "                           name='Intermediate Regression'))\n",
    "pd.DataFrame(error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
